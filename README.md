# TensorFlow
Repo con material para las sesiones de estudio de TensorFlow.

<div style="margin: 0 auto">
  <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/1/11/TensorFlowLogo.svg/1200px-TensorFlowLogo.svg.png" />
</div>

## Prerrequisitos
- [Colab: Python and Colab Primer](https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l01c01_introduction_to_colab_and_python.ipynb)

## Contenido
- Pronto

## Glosario de Términos

- Feature: El(los) input(s) para nuestro modelo
- Examples: Un par de entrada/salida usados para el entrenamiento
- Labels: La salida del modelo
- Layer: Una colección de nodos conectados dentro de una red neuronal
- Model: La representación de nuestra red neuronal
- Dense and Fully Connected (FC): Cada nodo en una capa está conectada con cada nodo de la capa anterior.
- Weights and biases: Son variables internas del modelo
- Loss: La discrepancia entre la salida deseada y la real
- MSE: Error cuadrado de la media (Mean squared error), es un tipo de función de pérdida que cuenta un número pequeño de grandes discrepancias como algo peor que un gran número de pequeñas discrepancias.
- Gradient Descent: Un algoritmo que cambia las variables internas un poco cada vez para reducir la función de pérdida.
- Optimizer: Una implementación específica del algoritmo de gradiente descendiente. (Hay muchos algoritmos para esto. Un tipo de implementación considerada como "best practice" es “Adam” Optimizer, que significa ADAptive con Momentum.)
- Learning rate:  El "step size" para mejorar la pérdida durante el descenso del gradiente.
- Batch: El conjunto de ejemplos utilizados durante el entrenamiento de la red neuronal.
- Epoch: Un recorrido completo por todo el conjunto de datos de entrenamiento
- Forward propagation (forward pass): El cálculo de los valores de salida a partir de la entrada.
- Backpropagation (backward pass): El cálculo de los ajustes de las variables internas de acuerdo con el algoritmo optimizador, comenzando desde la capa de salida y retrocediendo a través de cada capa hasta la entrada.

## Otros Notebooks

- [The Basics: Training Your First Model](https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l02c01_celsius_to_fahrenheit.ipynb)

## Libros Recomendados

- [AI and Machine Learning for Coders](https://www.oreilly.com/library/view/ai-and-machine/9781492078180)
- [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition)
- [Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632)
- [Deep Learning](https://www.deeplearningbook.org)
- [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com)
- [Learning TensorFlow.js](https://www.oreilly.com/library/view/learning-tensorflowjs/9781492090786)
- [Deep Learning with JavaScript](https://www.manning.com/books/deep-learning-with-javascript)

## Playlists Recomendadas

- [TensorFlow in Google Colaboratory](https://www.youtube.com/playlist?list=PLQY2H8rRoyvyK5aEDAI3wUUqC_F0oEroL)
- [ML Zero to Hero](https://www.youtube.com/playlist?list=PLQY2H8rRoyvwWuPiWnuTDBHe7I0fMSsfO)
- [Natural Language Processing (NLP) Zero to Hero](https://www.youtube.com/playlist?list=PLQY2H8rRoyvzDbLUZkbudP-MFQZwNmU4S)
- [Building recommendation systems with TensorFlow](https://www.youtube.com/playlist?list=PLQY2H8rRoyvy2MiyUBz5RWZr5MPFkV3qz)
- [TensorFlow and Google Cloud](https://www.youtube.com/playlist?list=PLQY2H8rRoyvwN2KcgCiApoDsVaxW64tNh)
- [Responsible AI](https://www.youtube.com/playlist?list=PLQY2H8rRoyvw40o-nd2CSrk-3JNMxW6er)

## Certificación

- [TensorFlow Developer Certificate](https://www.tensorflow.org/certificate)
